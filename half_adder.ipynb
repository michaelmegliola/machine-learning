{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The World's Least Efficient Adding Machine\n",
    "\n",
    "**A feed-forward neural network that trains to add 1 + 1 (in binary).**<br>\n",
    "\n",
    "$0+0=0$<br>\n",
    "$0+1=1$<br>\n",
    "$1+0=1$<br>\n",
    "$1+1=10$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "RESULTS\n",
      "0 + 0 = 0 0\n",
      "0 + 1 = 0 1\n",
      "1 + 0 = 0 1\n",
      "1 + 1 = 1 0\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0,0],[0,1],[0,1],[1,0]])\n",
    "hidden_size = 4\n",
    "W0 = 2 * np.random.random((2, hidden_size)) - 1\n",
    "W1 = 2 * np.random.random((hidden_size, 2)) - 1\n",
    "alpha = 0.05\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def sigmoid_to_sigmoid_prime(s_of_x):\n",
    "    return s_of_x * (1 - s_of_x)\n",
    "\n",
    "for i in range(0,100000):\n",
    "    # feed-forward values\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0, W0))  # multiply layer0 by weights, then activate\n",
    "    layer_2 = sigmoid(np.dot(layer_1, W1))\n",
    "    # back propogate errors\n",
    "    layer_2_error = y - layer_2\n",
    "    layer_2_delta = layer_2_error * sigmoid_to_sigmoid_prime(layer_2)\n",
    "    layer_1_error = layer_2_delta.dot(W1.T)\n",
    "    layer_1_delta = layer_1_error * sigmoid_to_sigmoid_prime(layer_1)\n",
    "    \n",
    "    W1 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "    W0 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "print('===========')\n",
    "print('RESULTS')\n",
    "for i in range(0, len(layer_2)):\n",
    "    a = 1 if layer_2[i][0] > 0.5 else 0\n",
    "    b = 1 if layer_2[i][1] > 0.5 else 0\n",
    "    print(X[i][0],'+',X[i][1],'=',a,b)\n",
    "print('===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================<br>\n",
    "Import numpy -- that handles linear algebra (and other useful math stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all possible inputs, as a numpy array (each row represents one set of inputs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the related (correct) set of outputs... the neural network will train to these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[0,0],[0,1],[0,1],[1,0]])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each input row relates 1:1 to an output row, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0] [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X[2],y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or to produce the entire truth table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] -> [0 0]\n",
      "[0 1] -> [0 1]\n",
      "[1 0] -> [0 1]\n",
      "[1 1] -> [1 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(X)):\n",
    "    print(X[i],'->',y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a neural network with one hidden layer; initialize random weights to allow forward propogation. The network will have one hidden layer. Start by specifying the size (width) of the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a random set of weights that allow inputs to be propogated into the hidden layer. One weight is required to represent the impact of each input on each node of the hidden layer. There are two inputs and four hidden nodes, so the weights need to be 2x4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24930343, -0.4406158 , -0.90512732,  0.7128532 ],\n",
       "       [-0.79008149, -0.73063072, -0.47393487, -0.71743393]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0 = 2 * np.random.random((2, hidden_size)) - 1\n",
    "W0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a random set of weights that allow outputs from the hidden layer to be propogated into outputs of the network. There are four nodes in the hidden layer, and two outputs, so the weights need to be 4x2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81445752,  0.12882471],\n",
       "       [ 0.90862417, -0.80702739],\n",
       "       [-0.32318397, -0.99912121],\n",
       "       [-0.10828113,  0.8507689 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = 2 * np.random.random((hidden_size, 2)) - 1\n",
    "W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a learning rate (errors will be incrementally corrected based on this rate, which may require tuning to get the correct results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a conventional function that converts a continuous result into a **yes** or **no**, more or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function works well because it **divides** continous inputs into *just-about-one* or *basically-zero*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faa302cc3c8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa3c7782b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(-10,10,0.1), sigmoid(np.arange(-10,10,.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the gradient of errors, it's also necessary to use the first derivative of that function, which is shaped in a way to say *get away from the transition... head for the extremes*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faa30231b70>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa302e5748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid_to_sigmoid_prime(s_of_x):\n",
    "    return s_of_x * (1 - s_of_x)\n",
    "\n",
    "plt.plot(np.arange(-10,10,0.1), sigmoid(np.arange(-10,10,.1)))\n",
    "plt.plot(np.arange(-10,10,0.1), sigmoid_to_sigmoid_prime(sigmoid(np.arange(-10,10,.1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is **forward propogation**. That is just the process of applying weights to inputs, *activating* the inputs using the sigmoid function (to cause each input to imply a result of **yes** or **no**), then using the resulting outputs as the input for the next layer of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the code in compact form...\n",
    "\n",
    "# feed-forward values\n",
    "layer_0 = X\n",
    "layer_1 = sigmoid(np.dot(layer_0, W0))  # multiply layer0 by weights, then activate\n",
    "layer_2 = sigmoid(np.dot(layer_1, W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is the code broken down into individual steps.\n",
    "\n",
    "# Step 1. The inputs to layer 0 are given by the data training set.\n",
    "layer_0 = X\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply the first set of weights by the matching set of inputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.79008149, -0.73063072, -0.47393487, -0.71743393],\n",
       "       [ 0.24930343, -0.4406158 , -0.90512732,  0.7128532 ],\n",
       "       [-0.54077806, -1.17124652, -1.37906218, -0.00458073]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this results is hard to understand... the next example is the same step, simplified.\n",
    "np.dot(layer_0, W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.2, 0.3, 0.4],\n",
       "       [0.5, 0.6, 0.7, 0.8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's invent some weights that are easier to understand, just to illustrate the math:\n",
    "W0 = np.array([[0.1,0.2,0.3,0.4],[0.5,0.6,0.7,0.8]])\n",
    "W0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(---inputs---------------)\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "(---weights--------------)\n",
      "[[0.1 0.2 0.3 0.4]\n",
      " [0.5 0.6 0.7 0.8]]\n",
      "(---dot-product----------)\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.5 0.6 0.7 0.8]\n",
      " [0.1 0.2 0.3 0.4]\n",
      " [0.6 0.8 1.  1.2]]\n"
     ]
    }
   ],
   "source": [
    "print('(---inputs---------------)')\n",
    "print(layer_0)\n",
    "print('(---weights--------------)')\n",
    "print(W0)\n",
    "print('(---dot-product----------)')\n",
    "print(np.dot(layer_0, W0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...so the dot product represents the sum of each input row, after multiplying each first element by the first row of weights, and each second element by the second row of weights. In effect, the dot product distributes the weights across the elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but!... it's not enough to simply weight the inputs. The network is designed to produce **yes** or **no** outputs, so each weighted input needs to be converted to a continuous version of **yes** or **no** by being *activated*. In this case, the *activation function* is the sigmoid function, applied to each weighted element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.62245933, 0.64565631, 0.66818777, 0.68997448],\n",
       "       [0.52497919, 0.549834  , 0.57444252, 0.59868766],\n",
       "       [0.64565631, 0.68997448, 0.73105858, 0.76852478]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = sigmoid(np.dot(layer_0, W0))\n",
    "layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer_1 is the intermediate state of the network... it represents the *output* that results from applying weights to the original inputs, and also the *input* to the second layer. In order for that step to succeed, the dimensions of the second set of weights must conform to the shape of the output of the first layer. It makes no difference the initial value of the weights... those will be corrected in the training process... but there must be one *row* of weights for each *column* of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "        [0.62245933, 0.64565631, 0.66818777, 0.68997448],\n",
       "        [0.52497919, 0.549834  , 0.57444252, 0.59868766],\n",
       "        [0.64565631, 0.68997448, 0.73105858, 0.76852478]]),\n",
       " array([[-0.81445752,  0.12882471],\n",
       "        [ 0.90862417, -0.80702739],\n",
       "        [-0.32318397, -0.99912121],\n",
       "        [-0.10828113,  0.8507689 ]]),\n",
       " array([[-0.16864923, -0.4132775 ],\n",
       "        [-0.21096655, -0.52146593],\n",
       "        [-0.17845798, -0.44069367],\n",
       "        [-0.21841529, -0.55023097]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1, W1, np.dot(layer_1, W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make that a little simpler to visualize... try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [2 2 2 2]\n",
      " [3 3 3 3]\n",
      " [4 4 4 4]]\n",
      "[[0 1 0 1]\n",
      " [0 2 0 2]\n",
      " [1 1 1 1]\n",
      " [2 2 2 2]]\n",
      "[[ 3  6  3  6]\n",
      " [ 6 12  6 12]\n",
      " [ 9 18  9 18]\n",
      " [12 24 12 24]]\n"
     ]
    }
   ],
   "source": [
    "l1 = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]])\n",
    "w1 = np.array([[0,1,0,1],[0,2,0,2],[1,1,1,1],[2,2,2,2]])\n",
    "print(l1)\n",
    "print(w1)\n",
    "print(np.dot(l1, w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway... layer_2 is the output of the network (which, of course, is wrong, but it's a start):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45793734, 0.3981265 ],\n",
       "       [0.44745311, 0.37250951],\n",
       "       [0.45550353, 0.39157569],\n",
       "       [0.44561222, 0.36581082]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly is the amount of error? The *error* is the difference between the expected outputs and the actual outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45793734, -0.3981265 ],\n",
       "       [-0.44745311,  0.62749049],\n",
       "       [-0.45550353,  0.60842431],\n",
       "       [ 0.55438778, -0.36581082]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure error in final layer by direct comparison to expected outputs\n",
    "layer_2_error = y - layer_2\n",
    "layer_2_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, only the error for the final layer (layer_2) is known, since that error can be measured by comparing layer_2 to the expected final state; however: the *results* of layer_2 imply the *errors* in layer_1. The process of using the results of each successive layer to estimate the error of the prior layer is called **back propogation**, because the errors are computed backwards, starting from a *direct* measurement at the final layer and proceeding **backwards** to an implied error of each *prior* layer.<p>\n",
    "In this step, layer_2 is sigmoid(input), layer_2_error is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11367412, -0.09539978],\n",
       "       [-0.11062778,  0.1466735 ],\n",
       "       [-0.11297402,  0.14495354],\n",
       "       [ 0.13695705, -0.08486565]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_delta = layer_2_error * sigmoid_to_sigmoid_prime(layer_2)\n",
    "layer_2_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
